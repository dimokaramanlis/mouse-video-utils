{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b4c7a0",
   "metadata": {},
   "source": [
    "# Run Deeplabut for freely moving box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e51955",
   "metadata": {},
   "source": [
    "We will first import the libraries needed. If you get an error, check that you're running the notebook inside the environment where DeepLabCut is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d7beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc8...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import os, glob, re, datetime, shutil\n",
    "import dlc_fun\n",
    "\n",
    "# we will set some general path identifiers here\n",
    "datapath       = 'S:\\\\ElboustaniLab\\\\#SHARE\\\\Data'\n",
    "jointmod       = '0Dyad_JointPerceptualDecisionMaking'\n",
    "ffmpegpath     = 'C:\\\\ffmpeg\\\\bin'\n",
    "filmidentifier = 'Filming'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010b145",
   "metadata": {},
   "source": [
    "We will now specify the model for analysis. Only one model is available, for unimplanted mice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe54ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_twomice = 'S:\\\\ElboustaniLab\\\\#SHARE\\\\Analysis\\\\JointDecisionDeepLabCut\\\\TwoMiceTorch-DK-2025-04-15'\n",
    "project_slider  = 'S:\\\\ElboustaniLab\\\\#SHARE\\\\Analysis\\\\JointDecisionDeepLabCut\\\\MouseSlider-DK-2025-04-15'\n",
    "config_twomice  = os.path.join(project_twomice,'config.yaml')\n",
    "config_slider   = os.path.join(project_slider,'config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d6f9b",
   "metadata": {},
   "source": [
    "### Find videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79263382",
   "metadata": {},
   "source": [
    "Specify the mouse or pair for which you want to perform the analysis. This string should match folder namings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d36ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mousefolders = ['YX018', 'YX019', 'YX020', 'YX021',  \n",
    "#                'Slider_YX015','Slider_YX014',\n",
    "#               'YX015', 'YX014', 'YX017', 'YX016']\n",
    "mousefolders = ['Slider_YX015','Slider_YX014']\n",
    "datestart    = '20220201'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4834eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX015\n",
      "2. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX014\n"
     ]
    }
   ],
   "source": [
    "mousepaths = []\n",
    "for imouse in range(len(mousefolders)):\n",
    "    if '_' in mousefolders[imouse]:\n",
    "        mousepaths.append(os.path.join(datapath, jointmod, mousefolders[imouse]))\n",
    "    else:\n",
    "        mousepaths.append(os.path.join(datapath, mousefolders[imouse]))\n",
    "        \n",
    "for impath in range(len(mousepaths)):\n",
    "    if os.path.isdir(mousepaths[impath]): \n",
    "        print(str(impath+1) + '. data path found: ' + mousepaths[impath])\n",
    "    else:\n",
    "        print(str(impath+1) + 'no such mouse or pair, check your list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "listvidpaths = []\n",
    "for imfold in range(len(mousepaths)):\n",
    "    allfpaths = dlc_fun.find_mp4_files(mousepaths[imfold])\n",
    "    listvidpaths.extend(allfpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d5738f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files were found that have not been analyzed:\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX014\\Filming\\SliderSingleMouse\\20250415\\Session1\\20250415_1627_Slider_YX014_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX015\\Filming\\SliderSingleMouse\\20250415\\Session1\\20250415_1833_Slider_YX015_3_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX014\\Filming\\SliderSingleMouse\\20250411\\Session1\\20250411_1851_Slider_YX014_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX014\\Filming\\SliderSingleMouse\\20250410\\Session1\\20250410_1916_Slider_YX014_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX015\\Filming\\SliderSingleMouse\\20250410\\Session1\\20250410_1823_Slider_YX015_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX014\\Filming\\SliderSingleMouse\\20250409\\Session1\\20250409_1938_Slider_YX014_2_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\0Dyad_JointPerceptualDecisionMaking\\Slider_YX015\\Filming\\SliderSingleMouse\\20250409\\Session1\\20250409_1900_Slider_YX015_1_reduced.mp4\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tuples (date, path)\n",
    "dated_paths = [(dlc_fun.extract_date(path), path) for path in listvidpaths]\n",
    "\n",
    "# Filter out None dates and sort the list by date\n",
    "sorted_paths = sorted((dp for dp in dated_paths if dp[0] is not None), key=lambda x: x[0])\n",
    "\n",
    "datethres    = datetime.datetime.strptime(datestart, '%Y%m%d')\n",
    "\n",
    "# Extract the sorted paths\n",
    "sorted_paths_only = [path for date, path in sorted_paths \n",
    "                     if datetime.datetime.strptime(date, '%Y%m%d') >= datethres and \n",
    "                     ('Unsorted' not in path) and ('Habituation' not in path) and \n",
    "                     ('Observational' not in path) and  ('ToSort' not in path) and  ('Direction' not in path)]\n",
    " \n",
    "# paths analyzed\n",
    "pathsold = [path for path in sorted_paths_only if not dlc_fun.to_analyze_dlc(path)]\n",
    "\n",
    "# clean up pickle and h5 pathsold\n",
    "for ipath in range(len(pathsold)):\n",
    "    dlc_fun.remove_big_files(os.path.splitext(pathsold[ipath])[0])\n",
    "        \n",
    "# paths to run DLC for\n",
    "pathsrun = [path for path in sorted_paths_only if dlc_fun.to_analyze_dlc(path)]\n",
    "pathsrun.reverse()\n",
    "\n",
    "if (len(sorted_paths_only)==0):\n",
    "    print('No video folder found.')\n",
    "else:\n",
    "    print('The following files were found that have not been analyzed:')\n",
    "    for ivid in range(len(pathsrun)):\n",
    "        print(pathsrun[ivid])\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e55d22-7de0-43fd-9c09-013546c6df7b",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc3b92-ed7e-4858-913a-e91536aa5a60",
   "metadata": {},
   "source": [
    "Let's run deeplabcut now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93956cb2-6450-4873-98f7-78bc9d2dd362",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file to C:\\Temp_proc\\20250415_1627_Slider_YX014_1_reduced.mp4\n",
      "Analyzing videos with S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\MouseSlider-DK-2025-04-15\\dlc-models-pytorch\\iteration-2\\MouseSliderApr15-trainset95shuffle1\\train\\snapshot-best-125.pt\n",
      "Starting to analyze C:\\Temp_proc\\20250415_1627_Slider_YX014_1_reduced.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    90304\n",
      "  Duration of video [s]:  3010.13\n",
      "  fps:                    30.0\n",
      "  resolution:             w=1408, h=1408\n",
      "\n",
      "Running pose prediction with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 90304/90304 [2:30:30<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...  C:\\Temp_proc\\20250415_1627_Slider_YX014_1_reduced.mp4\n",
      "Loading From C:\\Temp_proc\\20250415_1627_Slider_YX014_1_reducedDLC_DlcrnetStride32Ms5_MouseSliderApr15shuffle1_snapshot_125.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 90304/90304 [00:02<00:00, 40905.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created (i.e., under the hood deeplabcut.convert_detections2tracklets was run). Now you can 'refine_tracklets' in the GUI, or run 'deeplabcut.stitch_tracklets'.\n",
      "Processing...  C:\\Temp_proc\\20250415_1627_Slider_YX014_1_reduced.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\deeplabcut_torch\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py:939: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  df.to_hdf(output_name, \"tracks\", format=\"table\", mode=\"w\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed h5 file\n",
      "Copying file to C:\\Temp_proc\\20250415_1833_Slider_YX015_3_reduced.mp4\n",
      "Analyzing videos with S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\MouseSlider-DK-2025-04-15\\dlc-models-pytorch\\iteration-2\\MouseSliderApr15-trainset95shuffle1\\train\\snapshot-best-125.pt\n",
      "Starting to analyze C:\\Temp_proc\\20250415_1833_Slider_YX015_3_reduced.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    463384\n",
      "  Duration of video [s]:  15446.13\n",
      "  fps:                    30.0\n",
      "  resolution:             w=1408, h=1408\n",
      "\n",
      "Running pose prediction with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 616/463384 [01:00<12:33:48, 10.23it/s]"
     ]
    }
   ],
   "source": [
    "for ipath in range(len(pathsrun)):\n",
    "    \n",
    "    currpath = pathsrun[ipath]\n",
    "    # find if we can crop video\n",
    "    ispair   = jointmod in currpath\n",
    "    isslider = 'Slider' in currpath\n",
    "    skipcrop = ispair or isslider or ('Visual' in currpath)\n",
    "    \n",
    "    if isslider:\n",
    "        config = config_slider\n",
    "        nt     = 1\n",
    "    else:\n",
    "        config = config_twomice\n",
    "        nt     = 2\n",
    "    \n",
    "    if \"reduced\" in currpath.lower():\n",
    "        # video is already compressed by us\n",
    "        localpath = dlc_fun.copy_video_locally(currpath, 'C:\\\\Temp_proc')\n",
    "    else:\n",
    "        # we compress\n",
    "        localpath, status = dlc_fun.ffmpeg_compress_mp4_video(currpath, 'C:\\\\Temp_proc')\n",
    "                                                  \n",
    "    # do cropping\n",
    "    if skipcrop:\n",
    "        cropval = None\n",
    "    else:\n",
    "        cropval = dlc_fun.get_mouse_compartment(localpath)\n",
    "        \n",
    "    # run DLC locally\n",
    "    deeplabcut.analyze_videos(config, localpath, \n",
    "                              videotype = 'mp4', \n",
    "                              cropping = cropval,\n",
    "                              auto_track = True, \n",
    "                              n_tracks = nt, \n",
    "                              save_as_csv = True, \n",
    "                              batchsize = 4)\n",
    "    \n",
    "    csvpath = glob.glob(os.path.splitext(localpath)[0] + '*_el.csv')\n",
    "    \n",
    "    # if video was cropped, fix csv file\n",
    "    if not skipcrop:\n",
    "        dlc_fun.update_saved_csv(csvpath[0], cropval[2])\n",
    "\n",
    "    # move dlc csv back to path\n",
    "    shutil.copy2(csvpath[0], os.path.split(currpath)[0])\n",
    "    \n",
    "    # remove h5 and pickles after you're done, and other local files\n",
    "    dlc_fun.remove_big_files(os.path.splitext(localpath)[0])\n",
    "    os.remove(localpath)\n",
    "    os.remove(csvpath[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b4c7a0",
   "metadata": {},
   "source": [
    "# Run Deeplabut for freely moving box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e51955",
   "metadata": {},
   "source": [
    "We will first import the libraries needed. If you get an error, check that you're running the notebook inside the environment where DeepLabCut is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d7beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.10...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import os, glob, re, datetime, shutil\n",
    "import dlc_fun\n",
    "\n",
    "# we will set some general path identifiers here\n",
    "datapath       = 'S:\\\\ElboustaniLab\\\\#SHARE\\\\Data'\n",
    "jointmod       = '0Dyad_JointPerceptualDecisionMaking'\n",
    "filmidentifier = 'Filming'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010b145",
   "metadata": {},
   "source": [
    "We will now specify the model for analysis. Only one model is available, for unimplanted mice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe54ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectpath = 'S:\\\\ElboustaniLab\\\\#SHARE\\\\Analysis\\\\JointDecisionDeepLabCut\\\\NeuroPixelsBox-DK-2023-08-14'\n",
    "config      = os.path.join(projectpath,'config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d6f9b",
   "metadata": {},
   "source": [
    "### Find videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79263382",
   "metadata": {},
   "source": [
    "Specify the mouse or pair for which you want to perform the analysis. This string should match folder namings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d36ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mousefolders = ['YX001', 'YX002','YX003','YX004','YX005','YX006', 'YX007','YX008','YX009','YX010']\n",
    "#mousefolders = ['YX001', 'YX002','YX003','YX004','YX005','YX006', 'YX007','YX008','YX009','YX010']\n",
    "datestart    = '20220201'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4834eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX001\n",
      "2. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX002\n",
      "3. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX003\n",
      "4. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX004\n",
      "5. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX005\n",
      "6. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX006\n",
      "7. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX007\n",
      "8. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX008\n",
      "9. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX009\n",
      "10. data path found: S:\\ElboustaniLab\\#SHARE\\Data\\YX010\n"
     ]
    }
   ],
   "source": [
    "mousepaths = []\n",
    "for imouse in range(len(mousefolders)):\n",
    "    if '_' in mousefolders[imouse]:\n",
    "        mousepaths.append(os.path.join(datapath, jointmod, mousefolders[imouse]))\n",
    "    else:\n",
    "        mousepaths.append(os.path.join(datapath, mousefolders[imouse]))\n",
    "        \n",
    "for impath in range(len(mousepaths)):\n",
    "    if os.path.isdir(mousepaths[impath]): \n",
    "        print(str(impath+1) + '. data path found: ' + mousepaths[impath])\n",
    "    else:\n",
    "        print(str(impath+1) + 'no such mouse or pair, check your list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de7e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "listvidpaths = []\n",
    "for imfold in range(len(mousepaths)):\n",
    "    allfpaths = dlc_fun.find_mp4_files(mousepaths[imfold])\n",
    "    listvidpaths.extend(allfpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96d5738f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files were found that have not been analyzed:\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX009\\Filming\\OrientationSingleMouse\\20241120\\Session1\\20241120_1436_YX009_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX008\\Filming\\OrientationSingleMouse\\20241120\\Session1\\20241120_1319_YX008_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX007\\Filming\\OrientationSingleMouse\\20241120\\Session1\\20241120_1315_YX007_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX006\\Filming\\OrientationSingleMouse\\20241120\\Session1\\20241120_1312_YX006_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX002\\Filming\\Tests\\20241120\\Session1\\20241120_1441_YX002_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX010\\Filming\\OrientationSingleMouse\\20241119\\Session1\\20241119_1347_YX010_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX009\\Filming\\OrientationSingleMouse\\20241119\\Session1\\20241119_1353_YX009_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX008\\Filming\\OrientationSingleMouse\\20241119\\Session1\\20241119_1234_YX008_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX007\\Filming\\OrientationSingleMouse\\20241119\\Session1\\20241119_1230_YX007_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX006\\Filming\\OrientationSingleMouse\\20241119\\Session1\\20241119_1228_YX006_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX002\\Filming\\Tests\\20241119\\Session1\\20241119_1357_YX002_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX010\\Filming\\OrientationSingleMouse\\20241116\\Session1\\20241116_1452_YX010_2_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX009\\Filming\\OrientationSingleMouse\\20241116\\Session1\\20241116_1458_YX009_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX008\\Filming\\OrientationSingleMouse\\20241116\\Session1\\20241116_1348_YX008_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX007\\Filming\\OrientationSingleMouse\\20241116\\Session1\\20241116_1346_YX007_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX006\\Filming\\OrientationSingleMouse\\20241116\\Session1\\20241116_1344_YX006_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX003\\Filming\\ContrastSingleMouse\\20241116\\Session1\\20241116_1646_YX003_2.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX002\\Filming\\ContrastSingleMouse\\20241116\\Session2\\20241116_1614_YX002_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX002\\Filming\\ContrastSingleMouse\\20241116\\Session1\\20241116_1550_YX002_2.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX009\\Filming\\SequenceSingleMouse\\20241113\\Session1\\20241113_1445_YX009_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX007\\Filming\\SequenceSingleMouse\\20241113\\Session1\\20241113_1448_YX007_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX007\\Filming\\SequenceSingleMouse\\20241113\\Session1\\20241113_1448_YX007_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX006\\Filming\\SequenceSingleMouse\\20241113\\Session1\\20241113_1323_YX006_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX006\\Filming\\SequenceSingleMouse\\20241113\\Session1\\20241113_1323_YX006_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX010\\Filming\\SequenceSingleMouse\\20241112\\Session1\\20241112_1531_YX010_2_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX009\\Filming\\SequenceSingleMouse\\20241112\\Session1\\20241112_1529_YX009_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX008\\Filming\\SequenceSingleMouse\\20241112\\Session1\\20241112_1409_YX008_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX007\\Filming\\SequenceSingleMouse\\20241112\\Session1\\20241112_1407_YX007_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX006\\Filming\\SequenceSingleMouse\\20241112\\Session1\\20241112_1420_YX006_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX009\\Filming\\SequenceSingleMouse\\20241111\\Session1\\20241111_1755_YX009_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX008\\Filming\\SequenceSingleMouse\\20241111\\Session1\\20241111_1638_YX008_1.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX007\\Filming\\SequenceSingleMouse\\20241111\\Session1\\20241111_1636_YX007_1_reduced.mp4\n",
      "S:\\ElboustaniLab\\#SHARE\\Data\\YX006\\Filming\\SequenceSingleMouse\\20241111\\Session1\\20241111_1633_YX006_1_reduced.mp4\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tuples (date, path)\n",
    "dated_paths = [(dlc_fun.extract_date(path), path) for path in listvidpaths]\n",
    "\n",
    "# Filter out None dates and sort the list by date\n",
    "sorted_paths = sorted((dp for dp in dated_paths if dp[0] is not None), key=lambda x: x[0])\n",
    "\n",
    "datethres    = datetime.datetime.strptime(datestart, '%Y%m%d')\n",
    "\n",
    "# Extract the sorted paths\n",
    "sorted_paths_only = [path for date, path in sorted_paths \n",
    "                     if datetime.datetime.strptime(date, '%Y%m%d') >= datethres and \n",
    "                     ('Unsorted' not in path) and ('Habituation' not in path) and \n",
    "                     ('Observational' not in path) and  ('ToSort' not in path) and  ('Direction' not in path)]\n",
    " \n",
    "# paths analyzed\n",
    "pathsold = [path for path in sorted_paths_only if not dlc_fun.to_analyze_dlc(path)]\n",
    "\n",
    "# clean up pickle and h5 pathsold\n",
    "for ipath in range(len(pathsold)):\n",
    "    dlc_fun.remove_big_files(os.path.splitext(pathsold[ipath])[0])\n",
    "        \n",
    "# paths to run DLC for\n",
    "pathsrun = [path for path in sorted_paths_only if dlc_fun.to_analyze_dlc(path)]\n",
    "pathsrun.reverse()\n",
    "\n",
    "if (len(sorted_paths_only)==0):\n",
    "    print('No video folder found.')\n",
    "else:\n",
    "    print('The following files were found that have not been analyzed:')\n",
    "    for ivid in range(len(pathsrun)):\n",
    "        print(pathsrun[ivid])\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e55d22-7de0-43fd-9c09-013546c6df7b",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc3b92-ed7e-4858-913a-e91536aa5a60",
   "metadata": {},
   "source": [
    "Let's run deeplabcut now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93956cb2-6450-4873-98f7-78bc9d2dd362",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file to C:\\Temp_proc\\20241120_1436_YX009_1_reduced.mp4\n",
      "determining mouse side...\n",
      "frames done:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [01:59<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034.8297204177663\n",
      "139.66017572691368\n",
      "mouse found at the TOP part of the video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [0, 1408, 0, 804]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-100000 for model S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\NeuroPixelsBox-DK-2023-08-14\\dlc-models\\iteration-3\\NeuroPixelsBoxAug14-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating extracting of PAFs\n",
      "Starting to analyze %  C:\\Temp_proc\\20241120_1436_YX009_1_reduced.mp4\n",
      "Loading  C:\\Temp_proc\\20241120_1436_YX009_1_reduced.mp4\n",
      "Duration of video [s]:  14264.67 , recorded with  30.0 fps!\n",
      "Overall # of frames:  427940  found with (before cropping) frame dimensions:  1408 1408\n",
      "Starting to extract posture from the video(s) with batchsize: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 427940/427940 [4:15:22<00:00, 27.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Analyzed. Saving results in C:\\Temp_proc...\n",
      "Using snapshot-100000 for model S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\NeuroPixelsBox-DK-2023-08-14\\dlc-models\\iteration-3\\NeuroPixelsBoxAug14-trainset95shuffle1\n",
      "Processing...  C:\\Temp_proc\\20241120_1436_YX009_1_reduced.mp4\n",
      "Analyzing C:\\Temp_proc\\20241120_1436_YX009_1_reducedDLC_resnet50_NeuroPixelsBoxAug14shuffle1_100000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "427940it [31:06, 229.27it/s]\n",
      "427940it [01:46, 4014.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created (i.e., under the hood deeplabcut.convert_detections2tracklets was run). Now you can 'refine_tracklets' in the GUI, or run 'deeplabcut.stitch_tracklets'.\n",
      "Processing...  C:\\Temp_proc\\20241120_1436_YX009_1_reduced.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 12.50it/s]\n",
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py:930: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  df.to_hdf(output_name, \"tracks\", format=\"table\", mode=\"w\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Time to assemble animals and track 'em... \n",
      " Call 'create_video_with_all_detections' to check multi-animal detection quality before tracking.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed h5 file\n",
      "Copying file to C:\\Temp_proc\\20241120_1319_YX008_1.mp4\n",
      "determining mouse side...\n",
      "frames done:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [02:04<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673.1029171296884\n",
      "316.85391753601743\n",
      "mouse found at the TOP part of the video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [0, 1408, 0, 804]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-100000 for model S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\NeuroPixelsBox-DK-2023-08-14\\dlc-models\\iteration-3\\NeuroPixelsBoxAug14-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating extracting of PAFs\n",
      "Starting to analyze %  C:\\Temp_proc\\20241120_1319_YX008_1.mp4\n",
      "Loading  C:\\Temp_proc\\20241120_1319_YX008_1.mp4\n",
      "Duration of video [s]:  18747.9 , recorded with  30.0 fps!\n",
      "Overall # of frames:  562437  found with (before cropping) frame dimensions:  1408 1408\n",
      "Starting to extract posture from the video(s) with batchsize: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 562437/562437 [5:30:43<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Analyzed. Saving results in C:\\Temp_proc...\n",
      "Using snapshot-100000 for model S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\NeuroPixelsBox-DK-2023-08-14\\dlc-models\\iteration-3\\NeuroPixelsBoxAug14-trainset95shuffle1\n",
      "Processing...  C:\\Temp_proc\\20241120_1319_YX008_1.mp4\n",
      "Analyzing C:\\Temp_proc\\20241120_1319_YX008_1DLC_resnet50_NeuroPixelsBoxAug14shuffle1_100000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "562437it [50:33, 185.43it/s]\n",
      "562437it [02:41, 3492.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created (i.e., under the hood deeplabcut.convert_detections2tracklets was run). Now you can 'refine_tracklets' in the GUI, or run 'deeplabcut.stitch_tracklets'.\n",
      "Processing...  C:\\Temp_proc\\20241120_1319_YX008_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 61.92it/s]\n",
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py:930: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  df.to_hdf(output_name, \"tracks\", format=\"table\", mode=\"w\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Time to assemble animals and track 'em... \n",
      " Call 'create_video_with_all_detections' to check multi-animal detection quality before tracking.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed h5 file\n",
      "Copying file to C:\\Temp_proc\\20241120_1315_YX007_1.mp4\n",
      "determining mouse side...\n",
      "frames done:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [02:19<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631.4979036394667\n",
      "309.9751324578048\n",
      "mouse found at the TOP part of the video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [0, 1504, 0, 852]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-100000 for model S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\NeuroPixelsBox-DK-2023-08-14\\dlc-models\\iteration-3\\NeuroPixelsBoxAug14-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating extracting of PAFs\n",
      "Starting to analyze %  C:\\Temp_proc\\20241120_1315_YX007_1.mp4\n",
      "Loading  C:\\Temp_proc\\20241120_1315_YX007_1.mp4\n",
      "Duration of video [s]:  17379.0 , recorded with  30.0 fps!\n",
      "Overall # of frames:  521370  found with (before cropping) frame dimensions:  1504 1504\n",
      "Starting to extract posture from the video(s) with batchsize: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 521370/521370 [5:43:58<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Analyzed. Saving results in C:\\Temp_proc...\n",
      "Using snapshot-100000 for model S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\NeuroPixelsBox-DK-2023-08-14\\dlc-models\\iteration-3\\NeuroPixelsBoxAug14-trainset95shuffle1\n",
      "Processing...  C:\\Temp_proc\\20241120_1315_YX007_1.mp4\n",
      "Analyzing C:\\Temp_proc\\20241120_1315_YX007_1DLC_resnet50_NeuroPixelsBoxAug14shuffle1_100000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "521370it [44:09, 196.80it/s]\n",
      "521370it [02:15, 3848.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created (i.e., under the hood deeplabcut.convert_detections2tracklets was run). Now you can 'refine_tracklets' in the GUI, or run 'deeplabcut.stitch_tracklets'.\n",
      "Processing...  C:\\Temp_proc\\20241120_1315_YX007_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 196/196 [00:01<00:00, 107.01it/s]\n",
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\stitch.py:930: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  df.to_hdf(output_name, \"tracks\", format=\"table\", mode=\"w\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Time to assemble animals and track 'em... \n",
      " Call 'create_video_with_all_detections' to check multi-animal detection quality before tracking.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed pickle file\n",
      "removed h5 file\n",
      "Copying file to C:\\Temp_proc\\20241120_1312_YX006_1.mp4\n",
      "determining mouse side...\n",
      "frames done:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [01:59<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011.1729290070375\n",
      "154.36362871924445\n",
      "mouse found at the TOP part of the video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [0, 1408, 0, 804]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-100000 for model S:\\ElboustaniLab\\#SHARE\\Analysis\\JointDecisionDeepLabCut\\NeuroPixelsBox-DK-2023-08-14\\dlc-models\\iteration-3\\NeuroPixelsBoxAug14-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usr_m_elbousta1\\AppData\\Local\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating extracting of PAFs\n",
      "Starting to analyze %  C:\\Temp_proc\\20241120_1312_YX006_1.mp4\n",
      "Loading  C:\\Temp_proc\\20241120_1312_YX006_1.mp4\n",
      "Duration of video [s]:  19277.23 , recorded with  30.0 fps!\n",
      "Overall # of frames:  578317  found with (before cropping) frame dimensions:  1408 1408\n",
      "Starting to extract posture from the video(s) with batchsize: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                         | 3400/578317 [01:47<5:02:19, 31.69it/s]"
     ]
    }
   ],
   "source": [
    "for ipath in range(len(pathsrun)):\n",
    "    \n",
    "    currpath = pathsrun[ipath]\n",
    "    # find if we can crop video\n",
    "    ispair   = jointmod in currpath\n",
    "    skipcrop = ispair or ('Visual' in currpath)\n",
    "\n",
    "    localpath = dlc_fun.copy_video_locally(currpath, 'C:\\\\Temp_proc')\n",
    "\n",
    "    # do cropping\n",
    "    if skipcrop:\n",
    "        cropval = None\n",
    "    else:\n",
    "        cropval = dlc_fun.get_mouse_compartment(localpath)\n",
    "        \n",
    "    # run DLC locally\n",
    "    deeplabcut.analyze_videos(config, localpath, videotype = 'mp4', cropping = cropval,\n",
    "                              auto_track = True, n_tracks = 2, save_as_csv = True, batchsize = 4)\n",
    "    \n",
    "    csvpath = glob.glob(os.path.splitext(localpath)[0] + '*_el.csv')\n",
    "    \n",
    "    # if video was cropped, fix csv file\n",
    "    if not skipcrop:\n",
    "        dlc_fun.update_saved_csv(csvpath[0], cropval[2])\n",
    "\n",
    "    # move dlc csv back to path\n",
    "    shutil.copy2(csvpath[0], os.path.split(currpath)[0])\n",
    "    \n",
    "    # remove h5 and pickles after you're done, and other local files\n",
    "    dlc_fun.remove_big_files(os.path.splitext(localpath)[0])\n",
    "    os.remove(localpath)\n",
    "    os.remove(csvpath[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
